{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nne_DFrByoPA"
      },
      "source": [
        "# Introdução ao Pytorch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z66PPosgyoPD"
      },
      "source": [
        "O Pytorch é uma *framework* para aplicações de modelos de redes neurais. Toda sua documentação pode ser vista no site oficial do [Pytorch](https://pytorch.org/).\n",
        "\n",
        "Esse tutorial apresenta alguns passos introdutórios para produção dos modelos de Deep Learning que serão aplicados e foi baseado no tutorial oferecido pelo [Pytorch Tutorial](https://pytorch.org/tutorials/beginner/basics/intro.html).\n",
        "O tutorial tem os seguintes passos:\n",
        "- Tensores\n",
        "- Datasets e Dataloader\n",
        "- Construção do Modelo\n",
        "- Autograd\n",
        "- Treinamento do modelo\n",
        "- Salvamento e Carregamento do modelo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmWd-4XjyoPE"
      },
      "source": [
        "Primeiro, importa-se as bibliotecas necessárias para esse tutorial"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFjiLFxoyoPE"
      },
      "source": [
        "## Tensores\n",
        "\n",
        "Tensores são a estrutura de dados especializadas para os calculos dos parâmetros desejados dos modelos. Nesta sessão serão descritos como criar os tensores e algumas operações básicas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KeQMnSzEyoPF"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas necessárias para essa seção\n",
        "import torch\n",
        "import numpy as numpy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40PfMrRNyoPG"
      },
      "source": [
        "### Inicialização de Tensores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3irqHRmfyoPG"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNc4d6cfyoPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "951d1c6e-3c9d-4107-fadd-3eebb3a00828"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Valores a partir de uma lista: tensor([[1, 2],\n",
            "        [2, 4]])\n",
            "\n",
            "\n",
            "Valores a partir partir de um numpy array: [[1, 2], [2, 4]]\n",
            "\n",
            "\n",
            "Valores unitários a partir de um tensor: tensor([[1, 1],\n",
            "        [1, 1]])\n",
            "\n",
            "\n",
            "Valores aleatórios a partir de um tensor: tensor([[0.0173, 0.7524],\n",
            "        [0.8764, 0.7541]])\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Inicialização do Tensor a partir de uma lista\n",
        "data = [[1, 2], [2, 4]]\n",
        "x_data = torch.tensor(data)\n",
        "print(f\"Valores a partir de uma lista: {x_data}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Inicialização do Tensor a partir de um numpy array\n",
        "np_array = [[1, 2], [2, 4]]\n",
        "x_np = torch.tensor(np_array)\n",
        "print(f\"Valores a partir partir de um numpy array: {np_array}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Inicialização do Tensor a partir de outro tensor.\n",
        "# Valores unitários\n",
        "x_ones = torch.ones_like(x_data)\n",
        "print(f\"Valores unitários a partir de um tensor: {x_ones}\", end=\"\\n\\n\\n\")\n",
        "\n",
        "# Valores aleatórios\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float)\n",
        "print(f\"Valores aleatórios a partir de um tensor: {x_rand}\", end=\"\\n\\n\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EV_WD0Q0yoPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0190c1c4-e212-401b-db6d-919cd1eaf154"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dimensão do Tensor: torch.Size([3, 4])\n",
            "Tipo de dado do Tensor: torch.float32\n",
            "Device em que o Tensor está armazenado: cpu\n"
          ]
        }
      ],
      "source": [
        "# Alguns atributos do tensor\n",
        "tensor = torch.rand(3, 4)\n",
        "\n",
        "print(f\"Dimensão do Tensor: {tensor.shape}\")\n",
        "print(f\"Tipo de dado do Tensor: {tensor.dtype}\")\n",
        "print(f\"Device em que o Tensor está armazenado: {tensor.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A1TMyr3QyoPH"
      },
      "source": [
        "### Operações com Tensores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N7PHXWiyoPH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c81b28ac-b831-43c8-8156-0a7aea3700f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Primeira linha: tensor([1., 1., 1., 1.])\n",
            "Primeira coluna: tensor([1., 1., 1., 1.])\n",
            "Última coluna: tensor([1., 1., 1., 1.])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Indexing e Slicing:\n",
        "tensor = torch.ones(4, 4)\n",
        "print(f\"Primeira linha: {tensor[0]}\")\n",
        "print(f\"Primeira coluna: {tensor[:, 0]}\")\n",
        "print(f\"Última coluna: {tensor[..., -1]}\")\n",
        "\n",
        "tensor[:, 1] = 0\n",
        "tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H6hjNrWGyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86acd71f-9f14-4d28-b108-4e47c703ad7a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Concatenação de Tensores:\n",
        "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
        "t1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HWdDVlWjyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4356c22-23d1-40e4-9420-97419cbd0d2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7137, 0.3960, 0.3444, 0.3597],\n",
            "        [0.9143, 0.5665, 0.1483, 0.2012],\n",
            "        [0.0816, 0.0578, 0.2711, 0.5590]])\n",
            "tensor([[0.9355, 0.7338, 0.2782, 0.1287],\n",
            "        [0.1777, 0.2305, 0.8699, 0.3294],\n",
            "        [0.8455, 0.6220, 0.8112, 0.5545]])\n"
          ]
        }
      ],
      "source": [
        "# Operações aritméticas\n",
        "tensor1 = torch.rand(3, 4)\n",
        "tensor2 = torch.rand_like(tensor1)\n",
        "\n",
        "print(tensor1)\n",
        "print(tensor2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EQdfOrZByoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f48fb5e-aa98-4e5f-ca5d-10c53c45ea9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1.6492, 1.1298, 0.6226, 0.4884],\n",
            "        [1.0921, 0.7970, 1.0182, 0.5306],\n",
            "        [0.9271, 0.6798, 1.0824, 1.1136]])\n",
            "tensor([[-0.2218, -0.3378,  0.0662,  0.2310],\n",
            "        [ 0.7366,  0.3360, -0.7216, -0.1282],\n",
            "        [-0.7640, -0.5642, -0.5401,  0.0045]])\n"
          ]
        }
      ],
      "source": [
        "# Soma e Subtração (opera elemento a elemento)\n",
        "sum_tensor = tensor1 + tensor2\n",
        "sub_tensor = tensor1 - tensor2\n",
        "\n",
        "print(sum_tensor)\n",
        "print(sub_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r5Q-Lzn4yoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7333f8e-779e-410f-9a74-cbf135d6f33a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6677, 0.2906, 0.0958, 0.0463],\n",
            "        [0.1625, 0.1306, 0.1290, 0.0663],\n",
            "        [0.0690, 0.0359, 0.2199, 0.3100]])\n",
            "tensor([[0.7629, 0.5397, 1.2378, 2.7958],\n",
            "        [5.1447, 2.4572, 0.1705, 0.6109],\n",
            "        [0.0965, 0.0929, 0.3342, 1.0081]])\n"
          ]
        }
      ],
      "source": [
        "# Multiplicação e Divisão (opera elemento a elemento)\n",
        "mul_tensor = tensor1 * tensor2  ## ou torch.mul(tensor1, tensor2)\n",
        "div_tensor = tensor1 / tensor2  ## ou torch.div(tensor1, tensor2)\n",
        "\n",
        "print(mul_tensor)\n",
        "print(div_tensor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xByE4M2RyoPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b122dba1-68c9-48bb-ddfa-35efa52940c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Forma 1: tensor([[1.1003, 0.6362, 1.3286],\n",
            "        [1.3382, 0.4884, 1.3574],\n",
            "        [0.2660, 0.4478, 0.6349]])\n",
            "Forma 2: tensor([[1.1003, 0.6362, 1.3286],\n",
            "        [1.3382, 0.4884, 1.3574],\n",
            "        [0.2660, 0.4478, 0.6349]])\n"
          ]
        }
      ],
      "source": [
        "# Multiplicação Matricial sobre os tensores\n",
        "mul_mat_tensor1 = tensor1 @ tensor2.T  # Note: tensor2.T significa a transposição da matriz.\n",
        "mul_mat_tensor2 = torch.matmul(tensor1, tensor2.T)\n",
        "\n",
        "print(f\"Forma 1: {mul_mat_tensor1}\")\n",
        "print(f\"Forma 2: {mul_mat_tensor2}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MAZ-DJhyoPI"
      },
      "source": [
        "## Datasets e Dataloaders\n",
        "\n",
        "Datasets são os conjuntos de dados utilizado para treinamento dos parametros dos modelos. Dataloaders são a estrutura para treinamento dos modelos no qual será feita a separação de dos *minibatchs*, eleatorização dos dados etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7J8dHgPyoPJ"
      },
      "outputs": [],
      "source": [
        "# Bibliotecas necessárias para essa seção\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fc-rBXniyoPJ"
      },
      "source": [
        "### Dataset\n",
        "\n",
        "Esse exemplo faz o carregamento do dataset implementado na própria framework. Os dados utilizado aqui é o Fashion-MNIST. Outros datasets já implementados podem ser vistas em [Pytorch Dataset](https://pytorch.org/vision/stable/datasets.html)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcE4lrz5yoPJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be079f9b-459d-4b17-e507-29eb509e2db5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:02<00:00, 12848486.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 204755.69it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:01<00:00, 3750155.71it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 26558766.29it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Carregamento dos dados\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L9FZxdrWyoPJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "90e6fe03-dc94-4fbd-d6e3-82fbfc0b370b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x800 with 9 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Visualização dos datasets\n",
        "labels_map = {\n",
        "    0: \"T-Shirt\",\n",
        "    1: \"Trouser\",\n",
        "    2: \"Pullover\",\n",
        "    3: \"Dress\",\n",
        "    4: \"Coat\",\n",
        "    5: \"Sandal\",\n",
        "    6: \"Shirt\",\n",
        "    7: \"Sneaker\",\n",
        "    8: \"Bag\",\n",
        "    9: \"Ankle Boot\",\n",
        "}\n",
        "figure = plt.figure(figsize=(8, 8))\n",
        "cols, rows = 3, 3\n",
        "for i in range(1, cols * rows + 1):\n",
        "    sample_idx = torch.randint(len(training_data), size=(1,)).item()\n",
        "    img, label = training_data[sample_idx]\n",
        "    figure.add_subplot(rows, cols, i)\n",
        "    plt.title(labels_map[label])\n",
        "    plt.axis(\"off\")\n",
        "    plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3dm-dCfyoPJ"
      },
      "source": [
        "### Criando um Dataset customizável a partir de seus arquivos.\n",
        "\n",
        "Deve-se utilizar a class implementada no Pytorch (torch.utils.data.Dataset) e implementar três funções: *__init__*, *__len__* e *__getitem__*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qc2-h3RXyoPJ"
      },
      "outputs": [],
      "source": [
        "# Exemplo de um Dataset customizado\n",
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file)\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSdnvAQpyoPJ"
      },
      "source": [
        "### Preparação dos dados para treinamento.\n",
        "\n",
        "Após os datasets serem construídos, o próximo passo é montar o *dataloader*. No exemplo a seguir, utiliza-se a classe do Pytorch *torch.utils.data.DataLoader*.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLYJ-fCKyoPK"
      },
      "outputs": [],
      "source": [
        "# Construção dos dataloaders.\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxVFrzxHyoPK"
      },
      "source": [
        "### Iterando sobre o DataLoader."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EnE96VJ1yoPK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        },
        "outputId": "19093a8a-79e3-4fa9-bf8c-330259ca6783"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature batch shape: torch.Size([64, 1, 28, 28])\n",
            "Labels batch shape: torch.Size([64])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Label: 1\n"
          ]
        }
      ],
      "source": [
        "# Display image and label.\n",
        "train_features, train_labels = next(iter(train_dataloader))\n",
        "print(f\"Feature batch shape: {train_features.size()}\")\n",
        "print(f\"Labels batch shape: {train_labels.size()}\")\n",
        "img = train_features[0].squeeze()\n",
        "label = train_labels[0]\n",
        "plt.imshow(img, cmap=\"gray\")\n",
        "plt.show()\n",
        "print(f\"Label: {label}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeWxrDF3yoPK"
      },
      "source": [
        "## Construindo a Rede Neural\n",
        "\n",
        "Esta seção sera descrito a construção das redes neurais, como camadas e blocos. Os blocos imploementados podem ser vistos em [torch.nn](https://pytorch.org/docs/stable/nn.html), todas sendo subclasses do [nn.Module](https://pytorch.org/docs/stable/generated/torch.nn.Module.html)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms"
      ],
      "metadata": {
        "id": "PqW7xkLPzIPE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy9gw_ZNyoPK"
      },
      "source": [
        "### Utilização do dispositivo de treinamento\n",
        "\n",
        "Deve-se utilizar para treinar os modelos *hardwares* que acelerem, como GPU ou MPS, caso ,ão possua, utilize a própria CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OflLRxsvyoPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8d6b46a-f208-404d-916d-91de2635c263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ],
      "source": [
        "# Identificando o dispositivo disponível para treino.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iEUouO8yoPK"
      },
      "source": [
        "### Definição da Classe\n",
        "\n",
        "A classe que será a rede neural proposta deve ser uma subclasse de nn.Module e inicializa-se as camadas da rede a partir da função *__init__*. Após isso, deve ser implementada o método *forward*."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QKYHUt_cyoPK"
      },
      "outputs": [],
      "source": [
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXG6hqBbyoPK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ece4eba-6616-4802-d3e3-710059ef521f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Transferindo a rede neural para o dispositivo disponível.\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "asp4BDoDyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f750a6a0-5011-4d08-af0b-ecd0e41aeea4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted class: tensor([1], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "# Exemplo do forward implementado\n",
        "X = torch.rand(1, 28, 28, device=device)\n",
        "logits = model(X)\n",
        "pred_probab = nn.Softmax(dim=1)(logits)\n",
        "y_pred = pred_probab.argmax(1)\n",
        "print(f\"Predicted class: {y_pred}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Qq-xvMXyoPL"
      },
      "source": [
        "### Camadas do modelo\n",
        "\n",
        "Utilizando uma imagem colorida, com entradas RGB, tem-se que as imagens tem a seguinte dimensão: 3x28x28 (CxHxW), no qual C é o número de canais, H a altura da imagem e W a largura da imagem."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHC0Pok2yoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59d82c7-46e0-4c02-fc47-5a1a19ae2614"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 28, 28])\n"
          ]
        }
      ],
      "source": [
        "# Exemplo de uma imagem com entrada RGB\n",
        "input_image = torch.rand(3,28,28)\n",
        "print(input_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daEg_yjMyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5733da5-d513-4bb9-9194-6da66faa2011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 784])\n"
          ]
        }
      ],
      "source": [
        "# Flatten: Converte a imagem 28x28 para um array contínuo de 784 pixels.\n",
        "flatten = nn.Flatten()\n",
        "flat_image = flatten(input_image)\n",
        "print(flat_image.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLUaNi3byoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b822fcce-d955-458a-e89f-53f4213932f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([3, 20])\n"
          ]
        }
      ],
      "source": [
        "# nn.Linear é a camada totalmente conectada, no qual aplica a transformação linear, armazenando peso e bias.\n",
        "layer1 = nn.Linear(in_features=28*28, out_features=20)\n",
        "hidden1 = layer1(flat_image)\n",
        "print(hidden1.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z7UjYKRHyoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adc3a5dc-690c-428d-a174-77ac20c1cde6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before ReLU: tensor([[ 0.2732, -0.2663,  0.4725,  0.3270, -0.1425,  0.0799, -0.2182,  0.2543,\n",
            "         -0.2632, -0.3649,  0.1055, -0.0725,  0.1273,  0.2352, -0.0433, -0.1053,\n",
            "          0.3948, -0.4111, -0.3280, -0.5311],\n",
            "        [ 0.5290, -0.0831,  0.2832,  0.2170, -0.0851, -0.1747,  0.1477,  0.2340,\n",
            "         -0.5836, -0.1536,  0.1808, -0.2000, -0.1603,  0.1021, -0.3393,  0.1510,\n",
            "          0.2805, -0.1485, -0.2038, -0.4151],\n",
            "        [ 0.4756, -0.3913,  0.3602,  0.3477,  0.1892, -0.3841, -0.1668,  0.0456,\n",
            "         -0.3463,  0.0938, -0.0058, -0.2408, -0.2873, -0.1054, -0.1593, -0.1253,\n",
            "          0.5357, -0.3557, -0.3061, -0.3644]], grad_fn=<AddmmBackward0>)\n",
            "\n",
            "\n",
            "After ReLU: tensor([[0.2732, 0.0000, 0.4725, 0.3270, 0.0000, 0.0799, 0.0000, 0.2543, 0.0000,\n",
            "         0.0000, 0.1055, 0.0000, 0.1273, 0.2352, 0.0000, 0.0000, 0.3948, 0.0000,\n",
            "         0.0000, 0.0000],\n",
            "        [0.5290, 0.0000, 0.2832, 0.2170, 0.0000, 0.0000, 0.1477, 0.2340, 0.0000,\n",
            "         0.0000, 0.1808, 0.0000, 0.0000, 0.1021, 0.0000, 0.1510, 0.2805, 0.0000,\n",
            "         0.0000, 0.0000],\n",
            "        [0.4756, 0.0000, 0.3602, 0.3477, 0.1892, 0.0000, 0.0000, 0.0456, 0.0000,\n",
            "         0.0938, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5357, 0.0000,\n",
            "         0.0000, 0.0000]], grad_fn=<ReluBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# nn.ReLU, aplica a função de ativação ReLU aos valores de saída da rede.\n",
        "print(f\"Before ReLU: {hidden1}\\n\\n\")\n",
        "hidden1 = nn.ReLU()(hidden1)\n",
        "print(f\"After ReLU: {hidden1}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "04tbHu4KyoPP"
      },
      "outputs": [],
      "source": [
        "# nn.Sequencial, é o módulo de no qual agrupa todos os módulos de forma sequencial.\n",
        "seq_modules = nn.Sequential(\n",
        "    flatten,\n",
        "    layer1,\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 10)\n",
        ")\n",
        "input_image = torch.rand(3,28,28)\n",
        "logits = seq_modules(input_image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lzwsRwkWyoPQ"
      },
      "outputs": [],
      "source": [
        "# Softmax transforma os valores no intervalo (-inf, +inf) para escala [0, 1], representando a probablidade de cada classe e soma igual a 1.\n",
        "softmax = nn.Softmax(dim=1)\n",
        "pred_probab = softmax(logits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7O6ozDoyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a7b9518-a51e-4eb7-8971-6a5fe9f753d6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model structure: NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "\n",
            "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[-0.0166, -0.0023,  0.0095,  ..., -0.0309, -0.0341,  0.0257],\n",
            "        [ 0.0337, -0.0273,  0.0041,  ..., -0.0107, -0.0123, -0.0067]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0079,  0.0259], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[-0.0081,  0.0125,  0.0327,  ...,  0.0106,  0.0177, -0.0420],\n",
            "        [-0.0117, -0.0124, -0.0232,  ...,  0.0315,  0.0171, -0.0160]],\n",
            "       device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([ 0.0166, -0.0429], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[ 3.0008e-02,  3.3278e-02,  2.4694e-02,  ...,  1.4460e-02,\n",
            "         -1.2282e-02,  2.7259e-02],\n",
            "        [ 2.3344e-05,  1.3758e-02, -4.1854e-02,  ..., -1.9204e-02,\n",
            "          1.3760e-02,  1.5152e-02]], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n",
            "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([-0.0176, -0.0180], device='cuda:0', grad_fn=<SliceBackward0>) \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Representando os parâmetros dos modelos.\n",
        "print(f\"Model structure: {model}\\n\\n\")\n",
        "\n",
        "for name, param in model.named_parameters():\n",
        "    print(f\"Layer: {name} | Size: {param.size()} | Values : {param[:2]} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8XeSkUiyoPQ"
      },
      "source": [
        "## Autograd\n",
        "\n",
        "Ao treinar as redes neurais, os algoritmos de retropropagação (bachpropagation) são utilizados para ajustar os parâmetros dos modelos de acordo com os gradientes da função de perda.\n",
        "\n",
        "Para computar os gradientes, o Pytorch possui uma ferramenta chamada torch.autograd, no qual computa os gradientes de qualquer gráfico computacional. O exemplo a seguir mostra a saída dos gradientes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3iSceGZFyoPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "x = torch.ones(5)  # Tensor de entrada\n",
        "y = torch.zeros(3)  # Saída esperada\n",
        "w = torch.randn(5, 3, requires_grad=True) # Perceptron com 5 entradas e 3 saídas\n",
        "b = torch.randn(3, requires_grad=True)\n",
        "z = torch.matmul(x, w)+b\n",
        "loss = torch.nn.functional.binary_cross_entropy_with_logits(z, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7xXJy3nyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dcf12ae-8894-49d2-8595-924e72221628"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient function for z = <AddBackward0 object at 0x797e6bc62ce0>\n",
            "Gradient function for loss = <BinaryCrossEntropyWithLogitsBackward0 object at 0x797e6baa5690>\n"
          ]
        }
      ],
      "source": [
        "print(f\"Gradient function for z = {z.grad_fn}\")\n",
        "print(f\"Gradient function for loss = {loss.grad_fn}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pdvpWvQbyoPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "116c577e-af5f-462e-e026-91c4753e5a5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0220, 0.0050, 0.0692],\n",
            "        [0.0220, 0.0050, 0.0692],\n",
            "        [0.0220, 0.0050, 0.0692],\n",
            "        [0.0220, 0.0050, 0.0692],\n",
            "        [0.0220, 0.0050, 0.0692]])\n",
            "tensor([0.0220, 0.0050, 0.0692])\n"
          ]
        }
      ],
      "source": [
        "# Computando os gradientes\n",
        "loss.backward()\n",
        "print(w.grad)\n",
        "print(b.grad)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g3XfSjJFyoPQ"
      },
      "source": [
        "## Treinamento do modelo\n",
        "\n",
        "Entendido os passos descritos anteriormente, agora deve-se treinar o modelo para ajustar os parâmetros e minimizar o erro associado as previsões.\n",
        "\n",
        "Recaptulando os códigos descritos anteriormente, temos:\n",
        "- O dataset que será utilizado, no caso Fashion MNIST;\n",
        "- O dataloader que fará os *minibatchs*\n",
        "- O modelo da rede neural"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OAM-BSYyoPQ"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor()\n",
        ")\n",
        "\n",
        "train_dataloader = DataLoader(training_data, batch_size=64)\n",
        "test_dataloader = DataLoader(test_data, batch_size=64)\n",
        "\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqbC1e7IyoPR"
      },
      "source": [
        "### Hiperparametros\n",
        "- **Number of Epochs** - Número de vezes que será iterado pelo dataset.\n",
        "- **Batch Size** - Número de dados utilizados em cada propagação da rede neural;\n",
        "- **Learning Rate** - Fator de aprendizado dos parâmetros dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TSqa5tQfyoPR"
      },
      "outputs": [],
      "source": [
        "learning_rate = 1e-3\n",
        "batch_size = 64\n",
        "epochs = 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idW8dRYMyoPR"
      },
      "source": [
        "### Treinamento\n",
        "\n",
        "Itera sobre os dados para convergir os parâmetros do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrY03wXCyoPR"
      },
      "outputs": [],
      "source": [
        "def train_loop(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    # Define o modelo para o modo de treinamento.\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # Computa as previsões e a perda\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmvsimZryoPR"
      },
      "source": [
        "### Validação/Teste\n",
        "\n",
        "Itera sobre o dataset para avaliar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHkyDD_gyoPR"
      },
      "outputs": [],
      "source": [
        "def test_loop(dataloader, model, loss_fn):\n",
        "    # Define o modelo para o modo de avaliação.\n",
        "    model.eval()\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    # Evaluating the model with torch.no_grad() ensures that no gradients are computed during test mode\n",
        "    # also serves to reduce unnecessary gradient computations and memory usage for tensors with requires_grad=True\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DKvN6AqxyoPR"
      },
      "source": [
        "### Função de Perda\n",
        "\n",
        "Função definida para minimizar e, assim, avaliar o desempenho do modelo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Ojg2IbVyoPS"
      },
      "outputs": [],
      "source": [
        "# Função escolhida: CrossEntropy\n",
        "loss_fn = nn.CrossEntropyLoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "masw9eemyoPS"
      },
      "source": [
        "### Otimizadores\n",
        "\n",
        "Processo de ajuste do modelo para reduzir o erro para cada passo do treino."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ODN6qcR8yoPS"
      },
      "outputs": [],
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ha0MG9LHyoPS"
      },
      "source": [
        "### Treinamento\n",
        "\n",
        "Agrupando todos os passos, temos:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-GQUEAd6yoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62b8fb6b-3c58-4ba0-e903-74b1ebcc393f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.299226  [   64/60000]\n",
            "loss: 2.283672  [ 6464/60000]\n",
            "loss: 2.268672  [12864/60000]\n",
            "loss: 2.267554  [19264/60000]\n",
            "loss: 2.246444  [25664/60000]\n",
            "loss: 2.218187  [32064/60000]\n",
            "loss: 2.228284  [38464/60000]\n",
            "loss: 2.190271  [44864/60000]\n",
            "loss: 2.188742  [51264/60000]\n",
            "loss: 2.163676  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 35.4%, Avg loss: 2.155708 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.164534  [   64/60000]\n",
            "loss: 2.150726  [ 6464/60000]\n",
            "loss: 2.101444  [12864/60000]\n",
            "loss: 2.127902  [19264/60000]\n",
            "loss: 2.062519  [25664/60000]\n",
            "loss: 2.006952  [32064/60000]\n",
            "loss: 2.037187  [38464/60000]\n",
            "loss: 1.955170  [44864/60000]\n",
            "loss: 1.963729  [51264/60000]\n",
            "loss: 1.899651  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.7%, Avg loss: 1.897357 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.924127  [   64/60000]\n",
            "loss: 1.893047  [ 6464/60000]\n",
            "loss: 1.788137  [12864/60000]\n",
            "loss: 1.841850  [19264/60000]\n",
            "loss: 1.710136  [25664/60000]\n",
            "loss: 1.671818  [32064/60000]\n",
            "loss: 1.690715  [38464/60000]\n",
            "loss: 1.594509  [44864/60000]\n",
            "loss: 1.619406  [51264/60000]\n",
            "loss: 1.520790  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 59.9%, Avg loss: 1.539224 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.602269  [   64/60000]\n",
            "loss: 1.564847  [ 6464/60000]\n",
            "loss: 1.426407  [12864/60000]\n",
            "loss: 1.502705  [19264/60000]\n",
            "loss: 1.368912  [25664/60000]\n",
            "loss: 1.378093  [32064/60000]\n",
            "loss: 1.381670  [38464/60000]\n",
            "loss: 1.311340  [44864/60000]\n",
            "loss: 1.342478  [51264/60000]\n",
            "loss: 1.246875  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 62.6%, Avg loss: 1.273188 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.352231  [   64/60000]\n",
            "loss: 1.326292  [ 6464/60000]\n",
            "loss: 1.171041  [12864/60000]\n",
            "loss: 1.276666  [19264/60000]\n",
            "loss: 1.143319  [25664/60000]\n",
            "loss: 1.182797  [32064/60000]\n",
            "loss: 1.188559  [38464/60000]\n",
            "loss: 1.130749  [44864/60000]\n",
            "loss: 1.166907  [51264/60000]\n",
            "loss: 1.083087  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 64.2%, Avg loss: 1.105973 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.182317  [   64/60000]\n",
            "loss: 1.172487  [ 6464/60000]\n",
            "loss: 1.002622  [12864/60000]\n",
            "loss: 1.134301  [19264/60000]\n",
            "loss: 1.002907  [25664/60000]\n",
            "loss: 1.051031  [32064/60000]\n",
            "loss: 1.068827  [38464/60000]\n",
            "loss: 1.014402  [44864/60000]\n",
            "loss: 1.051685  [51264/60000]\n",
            "loss: 0.979880  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 65.6%, Avg loss: 0.997405 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.062972  [   64/60000]\n",
            "loss: 1.071400  [ 6464/60000]\n",
            "loss: 0.886730  [12864/60000]\n",
            "loss: 1.039065  [19264/60000]\n",
            "loss: 0.913411  [25664/60000]\n",
            "loss: 0.957206  [32064/60000]\n",
            "loss: 0.990206  [38464/60000]\n",
            "loss: 0.937826  [44864/60000]\n",
            "loss: 0.970751  [51264/60000]\n",
            "loss: 0.910651  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 66.9%, Avg loss: 0.922852 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 0.974593  [   64/60000]\n",
            "loss: 1.000901  [ 6464/60000]\n",
            "loss: 0.803225  [12864/60000]\n",
            "loss: 0.971294  [19264/60000]\n",
            "loss: 0.853118  [25664/60000]\n",
            "loss: 0.887655  [32064/60000]\n",
            "loss: 0.935051  [38464/60000]\n",
            "loss: 0.886400  [44864/60000]\n",
            "loss: 0.911553  [51264/60000]\n",
            "loss: 0.860574  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 68.0%, Avg loss: 0.868753 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 0.906138  [   64/60000]\n",
            "loss: 0.948450  [ 6464/60000]\n",
            "loss: 0.740255  [12864/60000]\n",
            "loss: 0.920463  [19264/60000]\n",
            "loss: 0.809920  [25664/60000]\n",
            "loss: 0.834610  [32064/60000]\n",
            "loss: 0.893458  [38464/60000]\n",
            "loss: 0.850660  [44864/60000]\n",
            "loss: 0.866791  [51264/60000]\n",
            "loss: 0.821896  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 69.5%, Avg loss: 0.827590 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 0.851059  [   64/60000]\n",
            "loss: 0.907119  [ 6464/60000]\n",
            "loss: 0.690893  [12864/60000]\n",
            "loss: 0.881147  [19264/60000]\n",
            "loss: 0.776942  [25664/60000]\n",
            "loss: 0.793196  [32064/60000]\n",
            "loss: 0.860104  [38464/60000]\n",
            "loss: 0.824557  [44864/60000]\n",
            "loss: 0.831928  [51264/60000]\n",
            "loss: 0.790749  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 70.7%, Avg loss: 0.794937 \n",
            "\n",
            "Fim!\n"
          ]
        }
      ],
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
        "    test_loop(test_dataloader, model, loss_fn)\n",
        "print(\"Fim!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSto3oO-yoPS"
      },
      "source": [
        "## Salvar e Carregar os pesos dos modelos\n",
        "\n",
        "Nesta seção será descrita o salvamento de carregamento do modelo desejado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ED7uPRqwyoPS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J6rCGfcpyoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06396fa8-e0b0-4bf0-eadc-f1e17abd01b2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:06<00:00, 80.0MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Carregando pesos pré-treinados:\n",
        "model = models.vgg16(weights='IMAGENET1K_V1')\n",
        "torch.save(model.state_dict(), 'model_weights.pth')  # Salvando o modelo na máquina"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_-XHpp4yoPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fdd00d0-d521-4a17-ea5a-591dbd421f28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VGG(\n",
              "  (features): Sequential(\n",
              "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (3): ReLU(inplace=True)\n",
              "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (6): ReLU(inplace=True)\n",
              "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (8): ReLU(inplace=True)\n",
              "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): ReLU(inplace=True)\n",
              "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (13): ReLU(inplace=True)\n",
              "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (15): ReLU(inplace=True)\n",
              "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (18): ReLU(inplace=True)\n",
              "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (20): ReLU(inplace=True)\n",
              "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (22): ReLU(inplace=True)\n",
              "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (25): ReLU(inplace=True)\n",
              "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (27): ReLU(inplace=True)\n",
              "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (29): ReLU(inplace=True)\n",
              "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
              "  (classifier): Sequential(\n",
              "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
              "    (1): ReLU(inplace=True)\n",
              "    (2): Dropout(p=0.5, inplace=False)\n",
              "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
              "    (4): ReLU(inplace=True)\n",
              "    (5): Dropout(p=0.5, inplace=False)\n",
              "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "# Carregando modelo salvo na maquina:\n",
        "model = models.vgg16() # Pesos não especificado\n",
        "model.load_state_dict(torch.load('model_weights.pth'))\n",
        "model.eval()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}